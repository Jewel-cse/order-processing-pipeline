# Order Processing Pipeline

## ğŸ“– Project Overview

A robust, **eventâ€‘driven microservices** example that demonstrates an endâ€‘toâ€‘end order processing flow using **Apache Kafka (KRaft mode, no Zookeeper)**, **Spring Boot 3.5.7**, and **Docker**. The solution showcases resilient messaging patterns such as **retryable topics**, **deadâ€‘letter queues (DLQ)**, and realâ€‘time analytics with **Kafka Streams**.

---

## ï¿½ Project Structure

```text
order-processing-pipeline/
â”œâ”€ analytics-service/      # Kafka Streams service that aggregates daily spend per customer
â”œâ”€ event-contracts/        # Shared DTOs / event schemas
â”œâ”€ infrastructure/         # Dockerâ€‘Compose for Kafka (KRaft) & Kafdrop UI
â”œâ”€ order-service/          # Producer â€“ REST API to create orders
â”œâ”€ payment-service/        # Consumer â€“ processes payments, retries, DLQ handling
â”œâ”€ pom.xml                 # Maven parent POM
â””â”€ README.md               # This documentation
```

---

## âœ¨ Key Features

- **Eventâ€‘Driven Architecture** â€“ Services communicate asynchronously via Kafka topics.
- **KRaft Kafka** â€“ Modern Kafka deployment without Zookeeper.
- **Resiliency** â€“ Automatic retries with configurable backâ€‘off and DLQ for poison messages.
- **Realâ€‘Time Analytics** â€“ `analyticsâ€‘service` uses Kafka Streams to compute daily spend per customer.
- **Infrastructure as Code** â€“ Oneâ€‘click Kafka cluster setup via Dockerâ€‘Compose.
- **Observability** â€“ Spring Actuator endpoints and Kafdrop UI for topic inspection.

---

## ğŸ› ï¸ Tech Stack

| Category | Technology |
|----------|------------|
| **JDK** | **Java 21** |
| **Framework** | **Spring Boot 3.5.7** |
| **Messaging** | **Apache Kafka 3.x (KRaft mode)** |
| **Containerisation** | **Docker & Dockerâ€‘Compose** |
| **Build** | **Maven** |
| **Testing** | **JUnit 5, Testcontainers** |

---

## âš™ï¸ Getting Started

### Prerequisites

- **Java 21** (ensure `JAVA_HOME` points to a JDKâ€¯21 installation)
- **Docker Desktop** (running)
- **Maven** (`mvn` on the PATH)

### Stepâ€‘byâ€‘Step

1. **Start the Kafka infrastructure** (KRaft, no Zookeeper)
   ```bash
   cd infrastructure
   docker-compose up -d
   ```
   This brings up a singleâ€‘node Kafka broker and the Kafdrop UI (http://localhost:9000).

2. **Build all modules**
   ```bash
   cd ..   # back to repository root
   mvn clean install
   ```
   Maven compiles the code, runs unit tests, and packages each service.

3. **Run the services** (open three terminals, one per service)
   ```bash
   # Terminal 1 â€“ Order Service
   cd order-service
   mvn spring-boot:run
   ```
   ```bash
   # Terminal 2 â€“ Payment Service
   cd payment-service
   mvn spring-boot:run
   ```
   ```bash
   # Terminal 3 â€“ Analytics Service (optional, for spend queries)
   cd analytics-service
   mvn spring-boot:run
   ```

---

## ğŸ§ª How to Test

1. **Create an Order**
   ```bash
   curl -X POST http://localhost:8080/order/create \
        -H "Content-Type: application/json" \
        -d '{"customerId":"CUST789012","item":"Laptop","price":1200.00}'
   ```
   The order event is published to the `order-events` topic.

2. **Verify Payment Processing**
   - Check the logs of `payment-service`; you should see the order being consumed and the payment simulated.

3. **Query Daily Spend (String endpoint)**
   ```bash
   curl http://localhost:8081/analytics/daily-spend/CUST789012/2025-11-24
   ```
   Expected response:
   ```String
   "Customer CUST789012 spent 1200.0 on 2025-11-24"
   ```

4. **Test Failure & DLQ**
   ```bash
   curl -X POST http://localhost:8080/order/create \
        -H "Content-Type: application/json" \
        -d '{"customerId":"CUST789012","item":"Phone","price":13}'
   ```
   The payment service will retry three times and then move the message to the deadâ€‘letter topic `order-events-topic.DLT`. You can inspect it via Kafdrop:
   ```bash
   open http://localhost:9000
   ```

---

## ğŸš€ Future Improvements

- **Multiâ€‘node Kafka cluster** with partition & replica configuration.
- **Metrics & Alerting** â€“ Prometheus + Grafana for consumer lag, throughput, error rates.
- **Schema Registry** â€“ Confluent Schema Registry with Avro/Protobuf for strong contract enforcement.
- **Kubernetes Deployment** â€“ Helm charts for services and Kafka.
- **Endâ€‘toâ€‘End Test Suite** â€“ Simulate highâ€‘volume event flow using Testcontainers.
- **Security** â€“ TLS encryption and SASL authentication for Kafka communication.

---

## ğŸ¤ Contributing

Contributions are welcome! Fork the repository, create a feature branch, and submit a pull request. Ensure all tests pass and follow the existing code style.

---

*Happy coding!*
